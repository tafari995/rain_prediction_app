
I was interested in predicting the rainfall at my apartment using artificial intelligence. After trying some MLPs, LSTM, and GRU networks (and leaning lots along the way), I reflected on the memory requirements of LSTM and GRU, and concluded that a transformer model might be an effective way to capture the complexity of rainfall data without using all my RAM (or more accurately, using my cached memory effectively).

A kind rectruiter at Jane Street gave me the idea to learn pytorch by trying to succeed at a prediction task, like building an algorithmic trading system or predicting the weather, and I didn't want to both risk my own cash and give away profitable info publicly, so I decided on the weather. I decided to implement an encoder-decoder transformer with one attention head and one layer (though it is relatively easy to change these choices in my code; just make sure the number of features times the window size is divisible by the number of attention heads!). As far as python goes, I used numpy, pandas, linear regression from sklearn, matplotlib backends and figures, and sqlalchemy. I mainly execute raw SQL queries against a mysql database containing my data, because the performance advantage seems better to me then using the python methods in the sqlalchemy package. Previous versions of this code had a numba-powered 'data jiggler' which I was using to artifically extend the weather data I had stored, but this code didn't make it into the final project because I didn't like the results.

Since everyone is ~dying~ to know, yes, I absolutely did use AI to help me with this project! I mainly like Deepseek R1, which I use locally through the llm-axe project, and Claude which I use through the web browser. I found the code both models wrote to be bad, even with 1-2 follow-up prompts, but it very often runs which is ridiculously impressive. I typically ask deepseek my more in-depth questions, since I like the organization of its in-depth analyses, and I go to Claude with my short questions, since I like how Claude's ideas compound upon themselves for short prompts (and of course, for Anthropic's demonstrated commitment to safety). I have no idea how folks are successfully using AI to write entire projects, but I suspect it involves spending a good chunk on specialized agents and pro plans, and a very high initial time investment in prompting!

The parts of this project I am most proud of is that my transformer code runs (a shocking number of youtubers and professors have transformers on github that do not train on my cpu or gpu...). I was also really fascinated to learn how different programmers integrate SQL and the services built on top of it into their code, and I now see the advantages of effective databasing when working with data and doing machine learning. 

On the thornier side, I wanted to train the transformer on more data, save the model, and then integrate that training and saving into the flask app so that everyone could have accurate rain predictions (at least at one latitude longitude pair). Due to restrictions with the open-meteo api as a free service, I needed to train the model on a bit of data (about 20 days) at a time, and I needed to do that on a schedule, but experimentation was restricted. Additionally, it has been a few years since I was using a Linux operating system full time, but thanks to some bad graphics driver updates and some faulty configuration files I wrote, I spent about 100 hours over the last 3 months fixing my machine. My last thorn is that I think the most effective way to use a model like this is to deploy it on data that is constantly streaming, but I simply didn't take it this far. 

If you think of improvements as you read, feel free to message me on LinkedIn (www.linkedin.com/in/tafari-clarke-james), and I May implement some of the changes you send. Additionally, please be upfront if you represent a company or academic body, and are contacting me on their behalf. 

Thanks for reading :)




